{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import contractions\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nltk\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "id": "ac062c51b18a2824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/fma_cut100_echonest_lyrics_fake_country.csv', header=[0, 1])"
   ],
   "id": "1ea20c1116c3ce06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sample()",
   "id": "91bb706e5658e7ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics = ('track', 'lyrics')",
   "id": "9816be34044eef1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "def preprocess_for_nlp(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for preprocessing the lyrics column for NLP tasks\n",
    "    \n",
    "    Args:\n",
    "    data: pd.DataFrame - DataFrame with lyrics column\n",
    "    \"\"\"\n",
    "    punctuation_to_remove = string.punctuation.replace(\"'\", \"\")\n",
    "    data[lyrics] = data[lyrics].str.lower()\n",
    "    data[lyrics] = data[lyrics].str.replace('chorus','')\n",
    "    data[lyrics] = data[lyrics].str.replace('verse','')\n",
    "    data[lyrics] = data[lyrics].str.replace(f\"[{punctuation_to_remove}]\", \"\", regex=True)\n",
    "    data[lyrics] = data[lyrics].str.replace('2x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x2','')\n",
    "    data[lyrics] = data[lyrics].str.replace('3x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x3','')\n",
    "    data[lyrics] = data[lyrics].str.replace('4x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x4','')\n",
    "    data[lyrics] = data[lyrics].str.replace('5x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x5','')\n",
    "    data[lyrics] = data[lyrics].str.replace('6x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x6','')\n",
    "    data[lyrics] = data[lyrics].str.replace('7x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x7','')\n",
    "    data[lyrics] = data[lyrics].str.replace('8x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x8','')\n",
    "    data[lyrics] = data[lyrics].str.replace('9x','')\n",
    "    data[lyrics] = data[lyrics].str.replace('x9','')\n",
    "    data[lyrics] = data[lyrics].str.replace('\\n', ' ')\n",
    "    data[lyrics] = data[lyrics].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    return data"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_pre = preprocess_for_nlp(data=df)",
   "id": "28bc1ee181a3bc5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_pre.sample()",
   "id": "be618e0633044178",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We have to remove also the numbers\n",
    "def remove_numbers(df: pd.DataFrame, column) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for removing numbers from the column lyrics\n",
    "    \"\"\"\n",
    "    df[column] = df[column].str.replace(r'\\d+', '', regex=True)\n",
    "    df[column] = df[column].str.replace(\"'\",\"\")\n",
    "    return df\n",
    "\n",
    "df_pre = remove_numbers(df_pre, lyrics)"
   ],
   "id": "28f01bafcfa4468f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_pre.sample(5)",
   "id": "41112e37566ae36f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def handle_contractions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for handling contractions -> expanding them to full words f.ex. don't to do not\n",
    "    \n",
    "    Args:\n",
    "    df: pd.DataFrame - DataFrame with lyrics column\n",
    "    \"\"\"\n",
    "    tqdm.pandas(desc=\"Handling contractions\")\n",
    "    data = df.copy()\n",
    "    data[lyrics] = data[lyrics].progress_apply(lambda x: contractions.fix(x))\n",
    "    return data\n",
    "\n",
    "df_without_contractions = handle_contractions(df_pre)"
   ],
   "id": "34305364a5ec50ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_without_contractions.sample(5)",
   "id": "15663ee6cb5efed9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to lemmatize lyrics\n",
    "def lemmatize_lyrics(lyrics):\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Create sets\n",
    "tqdm.pandas()\n",
    "df['Lyrics_Lemmatized'] = df[lyrics].progress_apply(lemmatize_lyrics)"
   ],
   "id": "b0106aa5b27dd578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check when track language code is different than 'en' or NaN\n",
    "df['track', 'language_code'].value_counts()"
   ],
   "id": "23e63ed3a6217317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter out non-English lyrics -> delete row when it or es\n",
    "df = df[df['track', 'language_code'].isin(['en', np.nan])]"
   ],
   "id": "18203cbb642cf2c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Lyrics_Lemmatized'].sample(5)",
   "id": "cbd666259814de57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sort_values(('track', 'one_genre'), inplace=True)",
   "id": "2f98f59c14749e8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "device = 'mps'\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"distilroberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"distilroberta-base\",\n",
    "    num_labels=8,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/lyrics_genre_model_alphabetically.pt\", map_location=device, weights_only=True))\n",
    "model.to(device)\n",
    "model.eval() # Set model to evaluation mode"
   ],
   "id": "f47a1fa3e009e167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare labels\n",
    "y = df[('track','one_genre')]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = np.eye(len(label_encoder.classes_))[y]  # One-hot encode genres\n",
    "print(label_encoder.inverse_transform([0, 1, 2, 3, 4, 5, 6, 7]))\n",
    "X = df['Lyrics_Lemmatized']\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f'Data set: {X.shape[0]} samples')"
   ],
   "id": "ce36c0dbae7ffd7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LyricsGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": label,\n",
    "        }"
   ],
   "id": "8c1fa1fb43bc3e6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create datasets and dataloaders\n",
    "batch_size = 24\n",
    "\n",
    "dataset = LyricsGenreDataset(X, y, tokenizer)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "b3863a1452bbf6a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for batch in data_loader:\n",
    "        # Move inputs to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "\n",
    "        # Extract hidden states (use the last layer's hidden states)\n",
    "        hidden_states = outputs.hidden_states[-1]  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Perform pooling (e.g., mean pooling across sequence length)\n",
    "        pooled_features = hidden_states.mean(dim=1)  # Shape: (batch_size, hidden_dim)\n",
    "\n",
    "        # Collect features\n",
    "        features.append(pooled_features.cpu())"
   ],
   "id": "9d9195e8c14a8a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "features",
   "id": "511438ecde172964",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Concatenate features from all batches\n",
    "lyrics_features = torch.cat(features, dim=0)  # Shape: (num_samples, hidden_dim)"
   ],
   "id": "f81b9e1815956792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics_features_np = lyrics_features.numpy()",
   "id": "66c5935acf9d8605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics_features_np",
   "id": "a9b26ef0c89b3462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "labels = y.argmax(axis=1)",
   "id": "cf9d3ded3b4c393d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "labels",
   "id": "88803d6b3ca3dbd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.save(\"features/lyrics_features_2.npy\", lyrics_features_np)\n",
    "np.save(\"features/lyrics_labels_2.npy\", labels)"
   ],
   "id": "8ab902e5c06fb161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f667a7c9018ac13e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model_single_genre(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_preds, test_labels, test_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Get probabilities\n",
    "            probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "            test_probs.extend(probs)\n",
    "\n",
    "            test_preds.extend(np.argmax(probs, axis=1))\n",
    "            test_labels.extend(np.argmax(labels.cpu().numpy(), axis=1))\n",
    "\n",
    "    test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "    test_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(f\"Test F1 Score: {test_f1}\")\n",
    "\n",
    "    return test_labels, test_preds, test_probs\n",
    "\n",
    "# Run evaluation and get predictions and labels\n",
    "test_labels, test_preds, test_probs = evaluate_model_single_genre(model, data_loader, device)"
   ],
   "id": "97281c13d58d91ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classification_report_single_genre(test_preds, test_labels):\n",
    "    print(classification_report(test_labels, test_preds, target_names=list(label_encoder.classes_)))\n",
    "\n",
    "# Use this function as needed to print the classification report\n",
    "classification_report_single_genre(test_preds, test_labels)"
   ],
   "id": "a0b2746c0a85f411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def plot_single_confusion_matrix(test_labels, test_preds, label_names):\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Use latex\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "\n",
    "    # Plot Non-Normalized\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (Non-Normalized)\")\n",
    "    plt.ylabel(\"True Genre\")\n",
    "    plt.xlabel(\"Predicted Genre\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    colors = [\"#FFFFFF\", \"#455681\"]  # White to #455681 gradient\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom_white_to_blue\", colors)\n",
    "    \n",
    "    # Normalize the confusion matrix# \n",
    "    conf_matrix_norm = cm_normalized\n",
    "    \n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "    # Plot the normalized confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix_norm, cmap=custom_cmap, annot=True, fmt=\".2f\", xticklabels=label_names, yticklabels=label_names, vmax=1.0)\n",
    "    plt.xlabel(\"Predicted\", fontdict={\"fontsize\": 12})\n",
    "    plt.ylabel(\"True\", fontdict={\"fontsize\": 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_normalized_lyrics.eps\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot single confusion matrix\n",
    "plot_single_confusion_matrix(test_labels, test_preds, list(label_encoder.classes_))\n",
    "\n",
    "\n"
   ],
   "id": "32658f2cdeeec31f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print auc-roc curve for each class on one plot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Run evaluation and get predictions, labels, and probabilities\n",
    "\n",
    "# Get the true positive rate and false positive rate\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(8):  # Assuming 8 classes\n",
    "    fpr[i], tpr[i], _ = roc_curve((np.array(test_labels) == i).astype(int), np.array(test_probs)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    \n",
    "\n",
    "np.save(\"fpr_lyric_multi.npy\", fpr)\n",
    "np.save(\"tpr_lyric_multi.npy\", tpr)\n",
    "np.save(\"roc_auc_lyric_multi.npy\", roc_auc)\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(8):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\")  # Use label_encoder.classes_ for genre names\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "# Set style\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.style.context('tableau-colorblind10')\n",
    "\n",
    "plt.legend(loc=\"lower right\")  # Adjust legend location if needed\n",
    "plt.style.use('fast')\n",
    "plt.style.context('fast')\n",
    "plt.savefig(\"auc_roc_roberta.png\", dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "104833631694d9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "208bc7d35a8c1836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3021a3db74a0c146",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
