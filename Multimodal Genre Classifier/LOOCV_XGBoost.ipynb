{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apply LOOCV XGBoost to the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "\n",
    "# Load lyrics features from npy file\n",
    "lyrics_features = np.load('features/lyrics_features.npy')\n",
    "\n",
    "# Load audio features from npy file\n",
    "audio_features = np.load('features/features_audio.npy')\n",
    "\n",
    "# Load metadata features from npy file\n",
    "metadata_features = np.load('features/X_metadata.npy')\n",
    "\n",
    "# Load labels from npy file\n",
    "labels = np.load('features/labels_audio.npy') # all have the same labels"
   ],
   "id": "aececc3f1a9161bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics_features",
   "id": "4803561da2af4491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "audio_features",
   "id": "e7a3bb42bc7fe1ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metadata_features",
   "id": "75ed9124fb519620",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate all features\n",
    "X = np.concatenate((lyrics_features, audio_features, metadata_features), axis=1)"
   ],
   "id": "601a33ba0bd12faf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optimize with Optuna - objective is F1-Score\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define the search space\n",
    "\n",
    "    # Number of estimators\n",
    "    n_estimators = 1000\n",
    "    # Learning rate\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 0.1, log=True)\n",
    "    # Maximum depth\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 8)\n",
    "    # Subsample\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 0.7)\n",
    "    # Alpha - l1 regularization\n",
    "    alpha = trial.suggest_float('alpha', 0, 100)\n",
    "\n",
    "    \n",
    "    # Train LOOCV XGBoost on the dataset to predict the labels\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "        \n",
    "    for train_index, test_index in tqdm(loo.split(X), total=len(labels)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        \n",
    "        # Train XGBoost Classifier\n",
    "        model = xgb.XGBClassifier(objective='multi:softmax', n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, subsample=subsample, alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict class labels\n",
    "        y_pred.append(model.predict(X_test)[0])\n",
    "        y_true.append(y_test[0])\n",
    "    \n",
    "    # Convert predictions and true labels to numpy arrays\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "        \n",
    "    # Convert predictions and true labels to numpy arrays\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return f1"
   ],
   "id": "27e22aac7bbfccfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optimize the model\n",
    "study = optuna.create_study(direction='maximize', study_name='early_fusion_v2', storage='sqlite:///early_fusion.db', load_if_exists=True)\n",
    "study.optimize(objective, n_trials=3)"
   ],
   "id": "26de3944027683ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from itertools import cycle\n",
    "\n",
    "# Ensure X and labels are available before running\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "y_true = []  # True labels\n",
    "y_score = []  # Predicted probabilities\n",
    "\n",
    "for train_index, test_index in tqdm(loo.split(X), total=len(labels)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Train XGBoost Classifier\n",
    "    model = xgb.XGBClassifier(objective='multi:softmax', n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities instead of class labels\n",
    "    probas = model.predict_proba(X_test)[0]  # Probability distribution across classes\n",
    "    \n",
    "    y_score.append(probas)\n",
    "    y_true.append(y_test[0])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_score = np.array(y_score)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Print classification results\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, np.argmax(y_score, axis=1)))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, np.argmax(y_score, axis=1)))"
   ],
   "id": "a002bdfb7d1c5c62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ====== AUC-ROC Curve Plotting ======\n",
    "\n",
    "# Binarize the true labels for multi-class AUC-ROC computation\n",
    "n_classes = len(np.unique(y_true))\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "np.save(\"auc_roc/fpr_early.npy\", fpr)\n",
    "np.save(\"auc_roc/tpr_early.npy\", tpr)\n",
    "np.save(\"auc_roc/auc_roc_early.npy\", roc_auc)\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray'])\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve for class {i} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "# Use tableu style\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for Multi-Class Classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ],
   "id": "8eb7dea9983ca9d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genre_dict = {\n",
    "    0: 'Country',\n",
    "    1: 'Hip-Hop',\n",
    "    2: 'Indie',\n",
    "    3: 'Jazz',\n",
    "    4: 'Metal',\n",
    "    5: 'Pop',\n",
    "    6: 'Rap',\n",
    "    7: 'Rock'\n",
    "}"
   ],
   "id": "ddd5fa1bd6f5c7f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "# Save the model\n",
    "joblib.dump(model, 'models/early_fusion_xgboost.joblib')"
   ],
   "id": "4af173e07cde0a94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot MSE for each class with genre names\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(genre_dict.values(), mse)\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error for each genre')\n",
    "plt.show()"
   ],
   "id": "b337e442638696a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [\"white\", \"#455681\"]  # White to #455681 gradient\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_white_to_blue\", colors)"
   ],
   "id": "73c27adbc3ee00d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_single_confusion_matrix(test_labels, test_preds, label_names):\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Use latex\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "\n",
    "    # Plot Non-Normalized\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix (Non-Normalized)\")\n",
    "    plt.ylabel(\"True Genre\")\n",
    "    plt.xlabel(\"Predicted Genre\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    colors = [\"white\", \"#455681\"]  # White to #455681 gradient\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom_white_to_blue\", colors)\n",
    "    # Normalize the confusion matrix# \n",
    "    conf_matrix_norm = cm_normalized\n",
    "    \n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "    # Plot the normalized confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix_norm, cmap=custom_cmap, annot=True, fmt=\".2f\", xticklabels=genre_dict.values(),\n",
    "                yticklabels=genre_dict.values(), vmax=1.0)\n",
    "    plt.xlabel(\"Predicted\", fontdict={\"fontsize\": 12})\n",
    "    plt.ylabel(\"True\", fontdict={\"fontsize\": 12})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_normalized_loocv.eps\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot single confusion matrix\n",
    "plot_single_confusion_matrix(y_true, y_pred, list(genre_dict.values()))\n",
    "\n",
    "\n"
   ],
   "id": "2c3a8a6051b77867",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "# Load the trained XGBoost model\n",
    "model = joblib.load('models/early_fusion_xgboost.joblib')\n",
    "\n",
    "# Assuming X and labels are available\n",
    "y_true = np.array(labels)  # True labels\n",
    "y_pred = model.predict(X)  # Get predicted probabilities"
   ],
   "id": "25a2c4fbd468ce48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "ccd954e88505c530",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the predicted labels\n",
    "np.save('features/labels_audio_pred.npy', y_pred)"
   ],
   "id": "9f2be642cba1829e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_true, y_pred)\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('True vs Predicted')\n",
    "plt.show()"
   ],
   "id": "edb71dc30be7db33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ],
   "id": "df8cfc2dadc805ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "308d6d7f2724d750",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
